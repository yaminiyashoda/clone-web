<!DOCTYPE HTML>
<!--
	ZeroFour by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>


<!-- Mirrored from 2022.ieeeicme.org/tutorials.html by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 08 Jul 2022 07:35:23 GMT -->
<head>
	<title>Tutorials - ICME2022</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />

	<!-- Favicon -->
	<link rel="icon" href="assets/favicon.ico">

	<!-- Stylesheet -->
	<link href="../cdn.jsdelivr.net/npm/bootstrap%405.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
		integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
	<link rel="stylesheet" href="assets/css/main.css" />
</head>

<body class="no-sidebar is-preload">
	<div id="page-wrapper">

		<!-- Header Wrapper -->
		<div id="header-wrapper">
			<div class="container">
				<!-- Header -->
				<header id="header">
					<div class="inner">
						<!-- Nav Start -->
						<script src="assets/js/partials/navbar.js"></script>
						<!-- Nav End -->
					</div>
				</header>
			</div>
		</div>

		<!-- Main Wrapper -->
		<div id="main-wrapper">
			<div class="wrapper style2">
				<div class="inner">
					<section class="container box feature3">
						<header class="major text-center">
							<h2>Tutorials</h2>
						</header>
						<section class="text-justify">

							<!-- tutorial card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#tutorial-1" role="button" aria-expanded="false"
									aria-controls="tutorial-1">
									Network-Empowered Scalable, Reliable and Secure Media Delivery
								</a>

								<div id="tutorial-1" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Organizer</h4>
										<ul>
											<li>
												Ali C. Begen, Professor, Ozyegin University<br>
												(IEEE ComSoc Distinguished Lecturer for 2016-2020)
											</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Abstract</h4>
										<p>
											HTTP adaptive streaming is a complex technology with dynamics that need to
											be studied thoroughly. The experience from the deployments in the last 10+
											years suggests that streaming clients typically operate in an unfettered
											greedy mode and they are not necessarily designed to behave well in
											environments where other clients exist or network conditions can change
											dramatically. This largely stems from the fact that clients make only
											indirect observations at the application (HTTP) layer (and limitedly at the
											transport layer, if any at all). Typically, there are three primary camps
											when it comes to scaling and improving streaming systems: (ùëñ) servers
											control client‚Äôs behavior/actions and the network uses appropriate QoS,
											(ùëñùëñ) servers and clients cooperate with each other and/or the network, or
											(ùëñùëñùëñ) clients stay in control and no cooperation with the servers or
											network is needed as long as there is enough capacity in the network (said
											differently, use dumb servers and network and throw more bandwidth at the
											problem). Intuitively, using hints should improve streaming since it helps
											the clients and servers take more appropriate actions. The improvement could
											be in terms of better viewer experience and supporting more viewers for the
											given amount of network resources, or the added capability to explicitly
											support controlled unfairness (as opposed to bitrate fairness) based on
											features such as content type, viewer profile and display characteristics.
										</p>
										<p class="mb-0">
											In this tutorial, we will examine the progress made in this area over the
											last several years, primarily focusing on the MPEG‚Äôs Server and Network
											Assisted DASH (SAND) and CTA‚Äôs Common Media Client/Server Data standards. We
											will also describe possible application scenarios and present an open-source
											sample implementation for the attendees to explore this topic further in
											their own, practical environments.
										</p>

										<h4 class="fw-bold border-bottom mb-2">Speaker Bio</h4>
										<div class="float-start mb-4">
											<img src="assets/images/tutorials/Ali_C_Begen.jpg"
												class="rounded float-start mb-2 me-3" style="width: 200px;" alt="">
											<p class="mb-0">
												<b>Ali C. Begen</b> is currently a computer science professor at Ozyegin
												University and a technical consultant in the Advanced Technology and
												Standards group at Comcast. Previously, he was a research and
												development
												engineer at Cisco. Begen received his PhD in electrical and computer
												engineering from Georgia Tech in 2006. To date he received a number of
												academic and industry awards, and was granted 30+ US patents. In 2020
												and
												2021, he was listed among the world's most influential scientists in the
												subfield of networking and telecommunications. More details are at
												<a href="https://ali.begen.net/">https://ali.begen.net</a>.
											</p>
										</div>
									</div>
								</div>
							</div>

							<!-- tutorial card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#tutorial-2" role="button" aria-expanded="false"
									aria-controls="tutorial-2">
									Edge-Cloud Collaborative Multimedia Analysis
								</a>

								<div id="tutorial-2" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Organizer</h4>
										<ul>
											<li>Ivan V. Bajiƒá, Professor, Simon Fraser University, Canada</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Abstract</h4>
										<p class="mb-0">
											Our world is at the beginning of the technological revolution that promises
											to transform the way we work, travel, learn, and live, through Artificial
											Intelligence (AI). While AI models have been making tremendous progress in
											research labs and overtaking scientific literature in many fields, efforts
											are now being made to take these models out of the lab and create products
											around them, which could compete with established technologies in terms of
											cost, reliability, and user trust, as well as enable new, previously
											unimagined applications. Foremost among these efforts involves bringing AI
											‚Äúto the edge‚Äù by pairing it with the multitude of sensors that is about to
											cover our world as part of the Internet of Things (IoT) and 5th generation
											(5G) communication network initiatives. This tutorial is about edge-cloud
											collaborative analysis of multimedia signals, which we shall refer to as
											Collaborative Intelligence (CI). This is a framework in which AI models,
											developed for multimedia signal analysis, are distributed between the edge
											devices and the cloud. In CI, typically, the front-end of an AI model is
											deployed on an edge device, where it performs initial processing and feature
											computation. These intermediate features are then sent to the cloud, where
											the back-end of the AI model completes the inference. CI has been shown to
											have the potential for energy and latency savings compared to the more
											typical cloud-based or fully edge-based AI model deployment, but it also
											introduces new challenges, which require new science and engineering
											principles to be developed in order to achieve optimal designs. In CI, a
											capacity-limited channel is inserted in the information pathway of an AI
											model. This necessitates compression of features computed at the edge
											sub-model, which in turn requires a solid understanding of the structure of
											the model‚Äôs latent space. Errors introduced into features due to channel
											imperfections would need to be handled at the cloud side in order to perform
											successful inference. Moreover, issues related to the privacy of transmitted
											data need to be addressed.
										</p>

										<h4 class="fw-bold border-bottom mb-2">Speaker Bio</h4>
										<div class="float-start mb-4">
											<img src="assets/images/tutorials/Ivan_Bajic.jpg"
												class="rounded float-start mb-2 me-3" style="width: 200px;" alt="">
											<p>
												<b>Ivan V. Bajiƒá</b> received the B.Sc.Eng. degree (summa cum laude) in
												Electronic Engineering from the University of Natal, South Africa, in
												1998, and the M.S. degree in Electrical Engineering, the M.S. degree in
												Mathematics, and the Ph.D. degree in Electrical Engineering from
												Rensselaer Polytechnic institute, Troy, NY, USA, in 2000, 2002, and
												2003, respectively. He was with the University of Miami 2003-2005,
												subsequently joining Simon Fraser University in Burnaby, BC, Canada,
												where he is currently a Professor of Engineering Science and co-director
												of the SFU Multimedia Lab. His research interests include signal
												processing and machine learning with applications to multimedia
												processing, compression, communications, and collaborative intelligence.
												His group‚Äôs work has received awards at ICME 2012 and ICIP 2019, and
												other recognitions (e.g., paper award finalist, top n%) at Asilomar,
												ICIP, ICME, and CVPR. It was also featured in the IEEE Signal Processing
												Magazine (May 2020), the front page of the IEEE Transactions on Audio,
												Speech, and Language Processing (July/August 2016), among the Featured
												Articles in IEEE Transactions on Image Processing and IEEE Transactions
												on Multimedia, as well as popular media such as Vancouver Sun, Plank
												Magazine, and CBC Radio. He has received an NSERC DAS Award in 2021 for
												his work on collaborative intelligence.
											</p>
											<p class="mb-0">
												Ivan is the incoming Chair (2022-2023) of the IEEE Multimedia Signal
												Processing Technical Committee and a Member of the IEEE Multimedia
												Systems and Applications Technical Committee. He has served on the
												organizing and/or program committees of the main conferences in his
												field, and has received several awards in these roles, including
												Outstanding Reviewer Award (five times), Outstanding Area Chair Award,
												and Outstanding Service Award. He was the Chair of the Vancouver Chapter
												of the IEEE Signal Processing Society 2013-2019, during which the
												Chapter received the Chapter of the Year Award from IEEE SPS. He was an
												Associate Editor of the IEEE Transactions on Multimedia and the IEEE
												Signal Processing Magazine, and is currently a Senior Area Editor of the
												IEEE Signal Processing Letters.
											</p>
										</div>
									</div>
								</div>
							</div>

							<!-- tutorial card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#tutorial-3" role="button" aria-expanded="false"
									aria-controls="tutorial-3">
									DeepFake Creation, Detection and Obstruction
								</a>

								<div id="tutorial-3" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Organizers</h4>
										<ul>
											<li>Yuezun Li, Professor, Ocean University of China, China</li>
											<li>Siwei Lyu, Professor, SUNY Buffalo, US</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Abstract</h4>
										<p class="mb-0">
											AI techniques, especially deep neural networks (DNNs) significantly improve
											the reality of falsified multimedia, leading to a severely disconcerting
											impact on society. In particular, the AI-based face forgery, known as
											DeepFake, is one of the most recent AI techniques that attracts increasing
											attention due to its ease of use and powerful performance. To counter the
											negative impact of DeepFake, the defense strategies are developed instantly
											such as the detection, ie, distinguishing forged content, and obstruction,
											ie, preventing the synthesis of forged content. In this tutorial, we plan to
											provide a review of the fundamentals in the creation of DeepFakes, and the
											recent advances in the detection and obstruction methods.
										</p>

										<h4 class="fw-bold border-bottom mb-2">Speaker Bios</h4>
										<div class="float-start mb-3">
											<img src="assets/images/tutorials/Yuezun_Li.jpg"
												class="rounded float-start mb-2 me-3" style="width: 200px;" alt="">
											<p class="mb-0">
												<b>Yuezun Li</b> is a lecturer in the Center on Artificial Intelligence,
												at Ocean University of China. He was a Senior Research Scientist at the
												Department of Computer Science and Engineering of University at Buffalo,
												SUNY from 2020.09 to 2020.12. He received Ph.D. degree in computer
												science at University at Albany, SUNY in 2020. He received M.S. degree
												in Computer Science in 2015 and B.S. degree in Software Engineering in
												2012 at Shandong University. Dr. Li‚Äôs research interest is mainly
												focused on artificial intelligence security and multimedia forensics.
												His work has been published in peer-reviewed conference and journals,
												including ICCV, CVPR, ICASSP, CVIU, etc.
											</p>
										</div>
										<div class="float-start mb-4">
											<img src="assets/images/tutorials/Siwei_Lyu.jpg"
												class="rounded float-start mb-2 me-3" style="width: 200px;" alt="">
											<p class="mb-0">
												<b>Siwei Lyu</b> is an SUNY Empire Innovation Professor at the
												Department of Computer Science and Engineering, the Director of UB Media
												Forensic Lab (UB MDFL), and the founding Co-Director of Center for
												Information Integrity (CII) of University at Buffalo, State University
												of New York. Dr. Lyu's research interests include digital media
												forensics, computer vision, and machine learning. Dr. Lyu has published
												over 170 refereed journal and conference papers. Dr. Lyu's research
												projects are funded by NSF, DARPA, NIJ, UTRC, IBM and Department of
												Homeland Security. He is the recipient of the IEEE Signal Processing
												SocietyBest Paper Award (2011), the National Science Foundation CAREER
												Award (2010), SUNY Albany's Presidential Award for Excellence in
												Research and Creative Activities (2017), SUNY Chancellor's Award for
												Excellence in Research and Creative Activities (2018) Google Faculty
												Research Award (2019), and IEEE Region 1 Technological Innovation
												(Academic) Award (2021). Dr. Lyu served on the IEEE Signal Processing
												Society's Information Forensics and Security Technical Committee (2016 -
												2021), and was on the Editorial Board of IEEE Transactions on
												Information Forensics and Security (2016-2021). Dr. Lyu is a Fellow of
												IEEE.
											</p>
										</div>
									</div>
								</div>
							</div>

							<!-- tutorial card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#tutorial-4" role="button" aria-expanded="false"
									aria-controls="tutorial-4">
									Tensor Computations for Multimedia Data Processing
								</a>

								<div id="tutorial-4" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Organizer</h4>
										<ul>
											<li>Yipeng Liu, Professor, University of Electronic Science and Technology
												of China</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Abstract</h4>
										<p class="mb-0">
											Many classical data processing methods rely on representation and
											computation in the form of vectors and matrices, where multi-dimensional
											data are unfolded into matrices for processing. However, the multi-linear
											structure would be lost in such vectorization or matricization, which leads
											to sub-optimal performance in processing. In fact, a natural representation
											for multi-dimensional data is a tensor. The tensor computation-based data
											processing methods can avoid multi-linear data structure loss in classical
											matrix based counterparts. The related advances in applied mathematics allow
											us to move from classical matrix based methods to tensor based methods for
											many applications, such as signal processing, machine learning,
											neuroscience, communication, psychometric, chemometrics, biometric, quantum
											Physics, quantum chemistry, etc. As typical kinds of multi- dimensional
											data, multimedia data could be more efficiently and effectively processed by
											tensor computations based data processing techniques. This tutorial will
											first provide a basic coverage of tensor notations, preliminary operations,
											main tensor decompositions and their properties. Based on them, a series of
											tensor based data processing methods are presented, as the multi-linear
											extensions of classical sparse learning, missing component analysis,
											principal component analysis, subspace cluster, linear regression, support
											vector machine, deep neural network, etc. The experimental results for a
											number of multimedia applications are given, such as image reconstruction,
											image quality enhancement, multimedia data fusion, background extraction,
											weather forecasting, pose estimation, source separation in speech, etc.
											Finally, some acceleration strategies are discussed for some more possible
											applications.
										</p>

										<h4 class="fw-bold border-bottom mb-2">Speaker Bio</h4>
										<div class="float-start mb-4">
											<img src="assets/images/tutorials/Yipeng_Liu.jpg"
												class="rounded float-start mb-2 me-3" style="width: 200px;" alt="">
											<p>
												<b>Yipeng Liu</b> received the BSc degree in biomedical engineering and
												the PhD degree in information and communication engineering from
												University of Electronic Science and Technology of China (UESTC),
												Chengdu, in 2006 and 2011, respectively. From 2011 to 2014, he was a
												research fellow at University of Leuven, Leuven, Belgium. Since 2014, he
												has been an associate professor with UESTC, Chengdu, China.
											</p>
											<p class="mb-0">
												His research interests are tensor computations for data processing. He
												has been developing new tensor decompositions and sparse optimizations
												for data processing techniques, including signal recovery, image quality
												enhancement, image and video compression, spectrum sensing and
												prediction, collaborative filtering, efficient neural networks,
												adversarial attack, anomaly detection, etc. He has co-authored two books
												titled ‚ÄúTensor Computation for Data Analysis‚Äù and ‚ÄúTensor Regression‚Äù
												published by Springer and Now Publishers, edited a book titled ‚ÄúTensors
												for Data Processing: Theory, Methods, and Applications‚Äù published by
												Elsevier, and authored or co-authored over 70 international journal and
												conference papers. He services as an associate editor for IEEE Signal
												Processing Letters, and the lead guest editor for the special issue
												‚Äútensor image processing‚Äù in Signal Processing: Image Communication. He
												has given tutorials for a few international conferences, including ISCAS
												2019, SiPS 2019, APSIPA ASC 2019, ICIP 2020, SSCI 2020, and VCIP 2021.
											</p>
										</div>
									</div>
								</div>
							</div>
						</section>
					</section>
				</div>
			</div>

			<!-- Sponsers -->
			<hr>
			<script src="assets/js/partials/sponsers.js"></script>
		</div>

		<!-- Footer Wrapper -->
		<script src="assets/js/partials/footer.js"></script>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="../cdn.jsdelivr.net/npm/bootstrap%405.1.3/dist/js/bootstrap.bundle.min.js"
		integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous">
		</script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>


<!-- Mirrored from 2022.ieeeicme.org/tutorials.html by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 08 Jul 2022 07:35:24 GMT -->
</html>