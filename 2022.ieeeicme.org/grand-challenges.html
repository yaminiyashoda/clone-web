<!DOCTYPE HTML>
<!--
	ZeroFour by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>


<!-- Mirrored from 2022.ieeeicme.org/grand-challenges.html by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 08 Jul 2022 07:35:34 GMT -->
<head>
	<title>Grand Challenges - ICME2022</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />

	<!-- Favicon -->
	<link rel="icon" href="assets/favicon.ico">

	<!-- Stylesheet -->
	<link href="../cdn.jsdelivr.net/npm/bootstrap%405.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
		integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
	<link rel="stylesheet" href="assets/css/main.css" />
</head>

<body class="no-sidebar is-preload">
	<div id="page-wrapper">

		<!-- Header Wrapper -->
		<div id="header-wrapper">
			<div class="container">
				<!-- Header -->
				<header id="header">
					<div class="inner">
						<!-- Nav Start -->
						<script src="assets/js/partials/navbar.js"></script>
						<!-- Nav End -->
					</div>
				</header>
			</div>
		</div>

		<!-- Main Wrapper -->
		<div id="main-wrapper">
			<div class="wrapper style2">
				<div class="inner">
					<section class="container box feature3">
						<header class="major text-center">
							<h2>Grand Challenges</h2>
						</header>
						<section class="text-justify">

							<!-- gc card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#gc-1" role="button" aria-expanded="false"
									aria-controls="gc-1">
									Low-power Deep Learning Semantic Segmentation Model Compression Competition for
									Traffic Scene in Asian Countries
								</a>

								<div id="gc-1" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Time</h4>
										<p>TBA</p>

										<h4 class="fw-bold border-bottom mb-2">Room</h4>
										<p>TBA</p>

										<h4 class="fw-bold border-bottom mb-2">Organizers</h4>
										<ul>
											<li>Ted Kuo</li>
											<li>Jenq-Neng Hwang</li>
											<li>Jiun-In Guo</li>
											<li>Marvin Chen</li>
											<li>Hsien-Kai Kuo</li>
											<li>Chia-Chi Tsai</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Website</h4>
										<p>
											<a href="https://aidea-web.tw/icme2022">https://aidea-web.tw/icme2022</a>
										</p>

										<h4 class="fw-bold border-bottom mb-2">Description</h4>
										<p>
											Object detection in the computer vision area has been extensively studied
											and making tremendous progress in recent years. Furthermore, image
											segmentation takes it to a new level by trying to find out accurately the
											exact boundary of the objects in the image. Semantic segmentation is in
											pursuit of more than just location of an object, going down to pixel level
											information. However, due to the heavy computation required in most deep
											learning-based algorithms, it is hard to run these models on embedded
											systems, which have limited computing capabilities. In addition, the
											existing open datasets for traffic scenes applied in ADAS applications
											usually include main lane, adjacent lanes, different lane marks (i.e. double
											line, single line, and dashed line) in western countries, which is not quite
											similar to that in Asian countries like Taiwan with lots of motorcycle
											riders speeding on city roads, such that the semantic segmentation models
											training by only using the existing open datasets will require extra
											technique for segmenting complex scenes in Asian countries.
										</p>
										<p>
											In this competition, we encourage the participants to design semantic
											segmentation model that can be applied in Taiwan’s traffic scene with lots
											of fast speeding motorcycles running on city roads along with vehicles and
											pedestrians. The developed models not only fit for embedded systems but also
											achieve high accuracy at the same time.
										</p>
										<p class="mb-1">
											This competition includes two stages: qualification and final competition.
										</p>
										<ul class="mb-3">
											<li>
												Qualification competition: all participants submit their answers online.
												A score is calculated. The top 15 teams would be qualified to enter the
												final round of the competition.
											</li>
											<li>
												Final competition: the final score will be evaluated on new MediaTek
												platform (Dimensity Series) platform for the final score.
											</li>
										</ul>
										<p>
											The goal is to design a lightweight deep learning semantic segmentation
											model suitable for constrained embedded system design to deal with traffic
											scenes in Asian countries like Taiwan. We focus on segmentation accuracy,
											power consumption, real-time performance optimization and the deployment on
											MediaTek’s Dimensity Series platform.
										</p>
										<p>
											With MediaTek’s Dimensity Series platform and its heterogeneous computing
											capabilities such as CPUs, GPUs and APUs (AI processing units) embedded into
											the system-on-chip products, developers are provided the high performance
											and power efficiency for building the AI features and applications.
											Developers can target these specific processing units within the
											system-on-chip or, they can also let MediaTek NeuroPilot SDK intelligently
											handle the processing allocation for them.
										</p>
										<p class="mb-0">
											Given the test image dataset, participants are asked to segment each pixel
											belonging to the following six classes {background, main_lane, alter_lane,
											double_line, dashed_line, single_line} in each image.
										</p>
									</div>
								</div>
							</div>


							<!-- gc card -->
							<div class="card mb-3">
								<a class="btn btn-light link-primary text-decoration-none text-start fs-6 fw-bold w-100 px-5 py-2"
									data-bs-toggle="collapse" href="#gc-2" role="button" aria-expanded="false"
									aria-controls="gc-2">
									Few-Shot Logo Detection in E-commerce
								</a>

								<div id="gc-2" class="collapse">
									<div class="card-body px-5 py-4">
										<h4 class="fw-bold border-bottom mt-0 mb-2">Time</h4>
										<p>TBA</p>

										<h4 class="fw-bold border-bottom mb-2">Room</h4>
										<p>TBA</p>

										<h4 class="fw-bold border-bottom mb-2">Organizers</h4>
										<ul>
											<li>Hui Xue, Alibaba Group, China</li>
											<li>Dong Li, Alibaba Group, China</li>
											<li>Weigao Wen, Alibaba Group, China</li>
											<li>Yuan He, Alibaba Group, China</li>
											<li>Xuan Jin, Alibaba Group, China</li>
											<li>Jianmin Pan, Alibaba Group, China</li>
											<li>Hang Su, Tsinghua University, China</li>
										</ul>

										<h4 class="fw-bold border-bottom mb-2">Website</h4>
										<p>
											<a
												href="https://tianchi.aliyun.com/competition/entrance/531948/introduction?lang=en-us">https://tianchi.aliyun.com/competition/entrance/531948/introduction?lang=en-us</a>
										</p>

										<h4 class="fw-bold border-bottom mb-2">Description</h4>
										<p>
											In e-commerce, logo detection of products can provide protection of the
											entrepreneurs’ and business owners’ hard-earned creations and ideas from
											malign usage and plagiarism. We propose the grand challenge of few-shot logo
											detection, which is a task that requires a model to detect logos by handling
											tiny logo instances, similar brands, and adversarial images at the same
											time, with limited annotations.
										</p>
										<p class="mb-0">
											This challenge aims to exchange ideas and discuss the problem for both
											academic and industrial researchers, and to seek a few-shot logo detection
											framework. We would like to characterize the properties that empower
											few-shot detection models, and to shed light on future directions for
											cross-community collaborations.
										</p>
									</div>
								</div>
							</div>


							<h3>Grand Challenge Chairs</h3>
							<ul>
								<li>Moi Hoon Yap (<a href="mailto:M.Yap@mmu.ac.uk">M.Yap@mmu.ac.uk</a>)</li>
								<li>Iulia Lefter (<a href="mailto:i.lefter@tudelft.nl">i.lefter@tudelft.nl</a>)</li>
								<li>Xin Wang (<a href="mailto:xin_wang@tsinghua.edu.cn">xin_wang@tsinghua.edu.cn</a>)
								</li>
							</ul>
						</section>
					</section>
				</div>
			</div>

			<!-- Sponsers -->
			<hr>
			<script src="assets/js/partials/sponsers.js"></script>
		</div>

		<!-- Footer Wrapper -->
		<script src="assets/js/partials/footer.js"></script>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="../cdn.jsdelivr.net/npm/bootstrap%405.1.3/dist/js/bootstrap.bundle.min.js"
		integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous">
		</script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>


<!-- Mirrored from 2022.ieeeicme.org/grand-challenges.html by HTTrack Website Copier/3.x [XR&CO'2014], Fri, 08 Jul 2022 07:35:34 GMT -->
</html>